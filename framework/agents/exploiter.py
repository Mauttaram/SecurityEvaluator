"""
Exploiter Agent - Generates attacks near discovered boundaries.

Implements targeted attack generation based on boundary information
from BoundaryProber agents.
"""

from typing import Any, Dict, List, Optional, Set
import random
from datetime import datetime

from ..base import UnifiedAgent, AgentCapabilities, Capability, AgentRole, Task, KnowledgeBase
from ..models import Attack, create_attack_id


class ExploiterAgent(UnifiedAgent):
    """
    Agent that generates attacks near weak boundaries.

    Uses three sources:
    1. Dataset (40%): Known attacks from datasets
    2. Programmatic (40%): Algorithmic variations
    3. LLM (20%): Creative novel attacks (optional)
    """

    def __init__(
        self,
        agent_id: str,
        knowledge_base: KnowledgeBase,
        scenario: 'SecurityScenario',
        use_llm: bool = False,
        llm_client: Optional[Any] = None,
        model_router: Optional[Any] = None
    ):
        """
        Initialize exploiter.

        Args:
            agent_id: Unique agent identifier
            knowledge_base: Shared knowledge base
            scenario: Security scenario
            use_llm: Whether to use LLM for creative generation
            llm_client: LLM client (required if use_llm=True)
            model_router: Optional model router for cost optimization
        """
        capabilities = AgentCapabilities(
            capabilities={Capability.GENERATE},
            role=AgentRole.EXPLOITER,
            requires_llm=use_llm,
            cost_per_invocation=0.05 if use_llm else 0.0,
            avg_latency_ms=1000.0 if use_llm else 50.0
        )
        super().__init__(agent_id, capabilities, knowledge_base)
        self.scenario = scenario
        self.use_llm = use_llm
        self.llm_client = llm_client
        self.model_router = model_router

        # Generation statistics
        self.attacks_generated = 0
        self.generation_sources = {'dataset': 0, 'programmatic': 0, 'llm': 0}

    def execute_task(self, task: Task) -> Any:
        """
        Execute attack generation task.

        Args:
            task: Task with parameters:
                - technique: Technique to exploit
                - num_attacks: Number of attacks to generate
                - boundary_info: Optional boundary information

        Returns:
            List of generated attacks
        """
        technique = task.parameters.get('technique')
        num_attacks = task.parameters.get('num_attacks', 50)
        boundary_info = task.parameters.get('boundary_info')

        if not technique:
            self.logger.error("Missing required parameter: technique")
            return {'error': 'Missing technique'}

        # Generate attacks
        attacks = self._generate_attacks(technique, num_attacks, boundary_info)

        # Share knowledge
        self.share_knowledge(
            entry_type='attack',
            data={
                'technique': technique,
                'num_attacks': len(attacks),
                'generation_sources': self.generation_sources,
                'attack_ids': [a.attack_id for a in attacks]
            },
            tags={'attack_generation', technique}
        )

        return {'attacks': attacks, 'count': len(attacks)}

    def _generate_attacks(
        self,
        technique: str,
        num_attacks: int,
        boundary_info: Optional[Dict[str, Any]] = None
    ) -> List[Attack]:
        """
        Generate attacks using hybrid approach.

        Args:
            technique: Attack technique
            num_attacks: Number of attacks to generate
            boundary_info: Optional boundary information for targeting

        Returns:
            List of generated attacks
        """
        attacks = []

        # Split generation: 40% dataset, 40% programmatic, 20% LLM
        num_dataset = int(num_attacks * 0.4)
        num_programmatic = int(num_attacks * 0.4)
        num_llm = num_attacks - num_dataset - num_programmatic if self.use_llm else 0

        # Adjust if no LLM
        if not self.use_llm and num_llm > 0:
            num_programmatic += num_llm
            num_llm = 0

        # 1. Dataset-based generation
        dataset_attacks = self._generate_from_dataset(technique, num_dataset)
        attacks.extend(dataset_attacks)
        self.generation_sources['dataset'] += len(dataset_attacks)

        # 2. Programmatic generation
        programmatic_attacks = self._generate_programmatic(technique, num_programmatic, boundary_info)
        attacks.extend(programmatic_attacks)
        self.generation_sources['programmatic'] += len(programmatic_attacks)

        # 3. LLM generation (if enabled)
        if self.use_llm and num_llm > 0:
            llm_attacks = self._generate_with_llm(technique, num_llm, boundary_info)
            attacks.extend(llm_attacks)
            self.generation_sources['llm'] += len(llm_attacks)

        self.attacks_generated += len(attacks)
        return attacks

    def _generate_from_dataset(self, technique: str, num_attacks: int) -> List[Attack]:
        """
        Generate attacks from baseline dataset.

        Args:
            technique: Attack technique
            num_attacks: Number of attacks

        Returns:
            List of attacks from dataset
        """
        baseline_dataset = self.scenario.get_baseline_dataset()
        if not baseline_dataset:
            return []

        # Filter by technique
        technique_attacks = [a for a in baseline_dataset if a.technique == technique]

        # Sample
        if len(technique_attacks) <= num_attacks:
            return technique_attacks
        else:
            return random.sample(technique_attacks, num_attacks)

    def _generate_programmatic(
        self,
        technique: str,
        num_attacks: int,
        boundary_info: Optional[Dict[str, Any]] = None
    ) -> List[Attack]:
        """
        Generate attacks programmatically.

        Args:
            technique: Attack technique
            num_attacks: Number of attacks
            boundary_info: Optional boundary information

        Returns:
            List of programmatically generated attacks
        """
        attacks = []

        # Get baseline attack
        baseline = self._get_baseline_attack(technique, boundary_info)

        # Generate variations
        for i in range(num_attacks):
            payload = self._create_variation(baseline, i)

            attack = self.scenario.create_attack(
                technique=technique,
                payload=payload,
                metadata={
                    'generation_source': 'programmatic',
                    'variation_index': i,
                    'baseline': baseline
                }
            )
            attack.created_by = self.agent_id
            attacks.append(attack)

        return attacks

    def _generate_with_llm(
        self,
        technique: str,
        num_attacks: int,
        boundary_info: Optional[Dict[str, Any]] = None
    ) -> List[Attack]:
        """
        Generate creative attacks using LLM.

        Args:
            technique: Attack technique
            num_attacks: Number of attacks
            boundary_info: Optional boundary information

        Returns:
            List of LLM-generated attacks
        """
        if not self.llm_client:
            self.logger.warning("LLM client not available, skipping LLM generation")
            return []

        attacks = []

        # Build prompt
        prompt = self._build_generation_prompt(technique, boundary_info)

        try:
            # Route to appropriate model if router available
            if self.model_router:
                task = Task(
                    task_id=f"gen_{technique}_{datetime.now().timestamp()}",
                    task_type='generate_attacks',
                    description=f"Generate {technique} attacks",
                    parameters={'technique': technique, 'num_attacks': num_attacks}
                )
                model_client = self.model_router.route(task, prompt)
                self.logger.info(f"Routed to model: {model_client.name}")
            else:
                model_client = self.llm_client

            # Call LLM
            response = model_client.generate(
                prompt=prompt,
                max_tokens=1000,
                temperature=0.9  # High creativity
            )

            # Parse response into attacks
            payloads = self._parse_llm_response(response)

            for i, payload in enumerate(payloads[:num_attacks]):
                attack = self.scenario.create_attack(
                    technique=technique,
                    payload=payload,
                    metadata={
                        'generation_source': 'llm',
                        'llm_model': model_client.name if hasattr(model_client, 'name') else 'unknown',
                        'prompt_used': prompt
                    }
                )
                attack.created_by = self.agent_id
                attacks.append(attack)

            # Update router with quality feedback
            if self.model_router:
                # Assess quality (simple heuristic: more attacks = better quality)
                quality_score = min(1.0, len(attacks) / num_attacks)
                self.model_router.update('generate_attacks', quality_score)

        except Exception as e:
            self.logger.error(f"LLM generation failed: {e}")

        return attacks

    def _get_baseline_attack(self, technique: str, boundary_info: Optional[Dict[str, Any]]) -> str:
        """
        Get baseline attack for variations.

        Args:
            technique: Attack technique
            boundary_info: Optional boundary information

        Returns:
            Baseline attack payload
        """
        # If boundary info provided, use weak boundary payload
        if boundary_info and 'payload' in boundary_info:
            return str(boundary_info['payload'])

        # Otherwise, use technique-specific default
        # (Should be overridden in scenario-specific implementations)
        return f"{technique}_baseline_attack"

    def _create_variation(self, baseline: str, index: int) -> str:
        """
        Create variation of baseline attack.

        Override in scenario-specific implementations.

        Args:
            baseline: Baseline payload
            index: Variation index

        Returns:
            Varied payload
        """
        # Default: Simple variation
        return f"{baseline}_var{index}"

    def _build_generation_prompt(self, technique: str, boundary_info: Optional[Dict[str, Any]]) -> str:
        """
        Build LLM prompt for attack generation.

        Args:
            technique: Attack technique
            boundary_info: Optional boundary information

        Returns:
            LLM prompt
        """
        prompt = f"""Generate creative {technique} attack payloads that may evade detection.

Technique: {technique}
Scenario: {self.scenario.get_name()}

"""

        if boundary_info:
            prompt += f"""Weak boundary detected:
- Payload: {boundary_info.get('payload', 'unknown')}
- Reason: {boundary_info.get('reason', 'unknown')}

Generate variations that exploit this weak boundary.
"""

        prompt += """
Generate 10 attack payloads, one per line.
Focus on novel, creative approaches that differ from common attacks.
"""

        return prompt

    def _parse_llm_response(self, response: str) -> List[str]:
        """
        Parse LLM response into payloads.

        Args:
            response: LLM response text

        Returns:
            List of payloads
        """
        # Simple parsing: One payload per line
        lines = response.strip().split('\n')
        payloads = [line.strip() for line in lines if line.strip()]
        return payloads

    def can_execute(self, task: Task) -> bool:
        """Check if agent can execute task."""
        return task.task_type in ['generate_attacks', 'exploit']

    def get_generation_stats(self) -> Dict[str, Any]:
        """
        Get generation statistics.

        Returns:
            Dictionary with generation stats
        """
        return {
            'total_generated': self.attacks_generated,
            'sources': self.generation_sources.copy(),
            'source_percentages': {
                k: (v / self.attacks_generated * 100) if self.attacks_generated > 0 else 0
                for k, v in self.generation_sources.items()
            }
        }
